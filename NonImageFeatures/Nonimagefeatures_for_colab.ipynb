{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jmwvFvmn2sgs"
   },
   "source": [
    "# Model Template for amliNet - set up to use non-image features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xL8mocUX2sgy"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import gc\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.utils import CustomObjectScope\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Flatten, Concatenate, MaxPool2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import itertools\n",
    "from contextlib import redirect_stdout\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 44626,
     "status": "ok",
     "timestamp": 1564413553322,
     "user": {
      "displayName": "Gabi Muir",
      "photoUrl": "",
      "userId": "11169522930486928965"
     },
     "user_tz": 240
    },
    "id": "eQNZhfjV22bR",
    "outputId": "a542b883-736c-4dab-f005-39f54ff6172e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ne1slP4yf9Km"
   },
   "outputs": [],
   "source": [
    "!unzip -q '/content/drive/My Drive/The Cool Kids/Data/CheXpert-v1.0-small.zip' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xz2shasV2sg-"
   },
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 420,
     "status": "ok",
     "timestamp": 1564424004386,
     "user": {
      "displayName": "Gabi Muir",
      "photoUrl": "",
      "userId": "11169522930486928965"
     },
     "user_tz": 240
    },
    "id": "9o2XZSN92shA",
    "outputId": "f22b148c-d627-47e1-f830-d29802fbb9ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did you mean to rename the model?\n"
     ]
    }
   ],
   "source": [
    "outcomes = ['No Finding',\n",
    "            'Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity',\n",
    "            'Lung Lesion', 'Edema', 'Consolidation', 'Pneumonia', 'Atelectasis',\n",
    "            'Pneumothorax', 'Pleural Effusion', 'Pleural Other', 'Fracture',\n",
    "            'Support Devices']\n",
    "pathologies = ['Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity',\n",
    "            'Lung Lesion', 'Edema', 'Consolidation', 'Pneumonia', 'Atelectasis',\n",
    "            'Pneumothorax', 'Pleural Effusion', 'Pleural Other', 'Fracture',\n",
    "            'Support Devices']\n",
    "\n",
    "#Edit these global variables\n",
    "PATH = 'CheXpert-v1.0-small'\n",
    "target = 'Lung Opacity'\n",
    "\n",
    "image_size = 256\n",
    "train_batch_size = 32\n",
    "val_batch_size = 32\n",
    "test_batch_size = 234\n",
    "\n",
    "train_set_size = 100000\n",
    "validation_percent = 0\n",
    "\n",
    "lr = 0.0001 #learning rate\n",
    "num_steps_per_epoch = 200 #can be set to none for auto choosing (does not work for multimodel)\n",
    "num_epochs = 30\n",
    "\n",
    "threshold = 0.5\n",
    "SEED = 12\n",
    "\n",
    "#create the directory before you start!\n",
    "model_name = 'multimodel_lungopacity'\n",
    "model_directory = 'multimodeltest_seed/' #model_name+'/' \n",
    "if os.path.isdir(model_directory):\n",
    "  print('Did you mean to rename the model?')\n",
    "  if not os.path.isdir(model_directory+'checkpoints/'):\n",
    "    os.makedirs(model_directory+'checkpoints/')\n",
    "else:\n",
    "  os.makedirs(model_directory)\n",
    "  os.makedirs(model_directory+'checkpoints/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L5gXB4Bu2shJ"
   },
   "source": [
    "### Save the hyperparameters used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 522,
     "status": "ok",
     "timestamp": 1564424007477,
     "user": {
      "displayName": "Gabi Muir",
      "photoUrl": "",
      "userId": "11169522930486928965"
     },
     "user_tz": 240
    },
    "id": "iauyb7wv2shL",
    "outputId": "d8c60f63-96f9-46b9-d658-7474d871ecde"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>multimodel_lungopacity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <td>Lung Opacity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Image size</th>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training batch size</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation batch size</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Testing batch size</th>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training Size</th>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Percent</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Learning Rate</th>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Steps per epoch</th>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of epochs</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Threshold</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      multimodel_lungopacity\n",
       "Target                          Lung Opacity\n",
       "Image size                               256\n",
       "Training batch size                       32\n",
       "Validation batch size                     32\n",
       "Testing batch size                       234\n",
       "Training Size                         100000\n",
       "Validation Percent                         0\n",
       "Learning Rate                         0.0001\n",
       "Steps per epoch                          200\n",
       "Number of epochs                          30\n",
       "Threshold                                0.5"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hyper_df = pd.DataFrame()\n",
    "hyper_df['Target'] = [target]\n",
    "hyper_df['Image size'] = [image_size]\n",
    "hyper_df['Training batch size'] = [train_batch_size]\n",
    "hyper_df['Validation batch size'] = [val_batch_size]\n",
    "hyper_df['Testing batch size'] = [test_batch_size]\n",
    "hyper_df['Training Size'] = [train_set_size]\n",
    "hyper_df['Validation Percent'] = [validation_percent]\n",
    "hyper_df['Learning Rate'] = [lr]\n",
    "hyper_df['Steps per epoch'] = [num_steps_per_epoch]\n",
    "hyper_df['Number of epochs'] = [num_epochs]\n",
    "hyper_df['Threshold'] = [threshold]\n",
    "\n",
    "hyper_df.index=[model_name]\n",
    "t = hyper_df.transpose()\n",
    "display(t)\n",
    "t.to_csv(model_directory+model_name+'hyperparameters.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hGWzlRjO2shW"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T02ZGPvT2shY"
   },
   "outputs": [],
   "source": [
    "def edit_urls(url):\n",
    "  ''' a function to edit the urls to the correct path using a global PATH variable declared earlier\n",
    "  '''\n",
    "  pieces = url.split('/')\n",
    "  newurl = ''\n",
    "\n",
    "    #removing the previous path 'CheXpert-v1.0-small' and including the PATH\n",
    "  for i, piece in enumerate(pieces):\n",
    "    if i > 0:\n",
    "      newurl+= '/' + piece\n",
    "    elif i == 0:\n",
    "      newurl += PATH\n",
    "\n",
    "  return newurl\n",
    "\n",
    "def clean_data(df):\n",
    "  '''\n",
    "  Edits the urls, fills the 'maybes' with yes and the nulls with no,\n",
    "  removes outlier ages (age 0 patients), removes 'unknown gender' patients,\n",
    "  collects which type of image it is\n",
    "  '''\n",
    "  df['Path'] = df['Path'].apply(edit_urls)\n",
    "  df[outcomes] = df[outcomes].fillna(0)\n",
    "  df[outcomes] = df[outcomes].replace(-1,1)\n",
    "  df = df[df['Age'] > 1]\n",
    "  df = df[(df['Sex'] == 'Male') | (df['Sex'] == 'Female')]\n",
    "  df['Image Type'] = df['AP/PA'].fillna('Lateral')\n",
    "  return df\n",
    "\n",
    "def stratify_training_set(df):\n",
    "  '''\n",
    "  Groups by the target so the training set has equal amounts of 'yes target' and 'no target'\n",
    "  '''\n",
    "  notarg = df[ df[target] == 0 ]\n",
    "  yestarg = df[ df[target] == 1]\n",
    "  print(f'There are {len(yestarg)} patients with {target}, compared to {len(notarg)} patients in the dataset without {target}')\n",
    "  print(f'{100* len(yestarg) / len(df)}% of patients have {target}')\n",
    "  if len(notarg) > len(yestarg):\n",
    "    print(f'{(len(notarg) - len(yestarg))} ({100*(len(notarg) - len(yestarg))/len(notarg)}%) of patients without {target} will be randomly removed from the sample pool')\n",
    "    notarg = notarg.sample(len(yestarg))\n",
    "  else:\n",
    "    print(f'{(len(yestarg) - len(notarg))} ({100*(len(yestarg) - len(notarg))/len(yestarg)}%)  of patients with {target} will be randomly removed from the sample pool')\n",
    "    yestarg = yestarg.sample(len(notarg))\n",
    "      \n",
    "  traindf = pd.concat([yestarg, notarg], axis=0)\n",
    "  traindf = traindf.sample(frac=1)\n",
    "  \n",
    "  return traindf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6JJnV9yM2shf"
   },
   "outputs": [],
   "source": [
    "def get_train_df(stratify = True):\n",
    "  '''\n",
    "  Returns the training dataframe, which has already been edited for \n",
    "  '''\n",
    "  train_df = clean_data( pd.read_csv(PATH + '/train.csv') )\n",
    "  \n",
    "  if stratify:\n",
    "    #stratify the training set by the target\n",
    "    train_df = stratify_training_set(train_df)\n",
    "\n",
    "  #can chose a subset here\n",
    "  if len(train_df) > train_set_size:\n",
    "    train_df = train_df.sample(train_set_size)\n",
    "\n",
    "  #for keras, make the target a string\n",
    "  train_df[target] = train_df[target].apply(str)\n",
    "  \n",
    "  print('training set:', train_df.shape)\n",
    "  display(train_df.head(3))\n",
    "  \n",
    "  return train_df\n",
    "  \n",
    "  \n",
    "def get_test_df():\n",
    "  test_df = clean_data( pd.read_csv(PATH + '/valid.csv'))\n",
    "  test_df[target] = test_df[target].apply(str)\n",
    "  print('test set:', test_df.shape)\n",
    "  return test_df\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "goASmVuw2shq"
   },
   "source": [
    "## Prepare the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QZUtlLfYLY4n"
   },
   "source": [
    "### without non-image features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10233,
     "status": "ok",
     "timestamp": 1564073856786,
     "user": {
      "displayName": "Gabi Muir",
      "photoUrl": "",
      "userId": "11169522930486928965"
     },
     "user_tz": 240
    },
    "id": "PJ-pr2X12shu",
    "outputId": "cfb9f7b0-a2bc-4952-c66b-2220257ca2e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9000 validated image filenames belonging to 2 classes.\n",
      "Found 1000 validated image filenames belonging to 2 classes.\n",
      "Found 234 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "   rescale = 1./255,\n",
    "   validation_split = validation_percent\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "   train_df,\n",
    "   x_col='Path',\n",
    "   y_col=target,\n",
    "   color_mode='grayscale', # images will be converted to have 1 color channel\n",
    "   target_size=(image_size, image_size), #The dimensions to which all images found will be resized\n",
    "   class_mode='binary', # Mode for yielding the targets 1D numpy array of binary labels,if class_mode is \"binary\" it must include the given y_col column with class values as strings.\n",
    "   batch_size=train_batch_size,\n",
    "   subset = \"training\"\n",
    "   #shuffle: whether to shuffle the data (default: True)\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_dataframe(\n",
    "   train_df,\n",
    "   x_col='Path',\n",
    "   y_col=target,\n",
    "   target_size=(image_size, image_size),\n",
    "   color_mode='grayscale',\n",
    "   class_mode='binary',\n",
    "   batch_size=val_batch_size,\n",
    "   subset = \"validation\"\n",
    ")\n",
    "\n",
    "test_generator = datagen.flow_from_dataframe(\n",
    "    test_df,\n",
    "    x_col='Path',\n",
    "    y_col=target,\n",
    "    target_size=(image_size, image_size),\n",
    "    color_mode='grayscale',\n",
    "    class_mode='binary',\n",
    "    batch_size=test_batch_size,\n",
    "    shuffle = False #just in case\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HuGmOHCa2sh4"
   },
   "source": [
    "## Edit your model here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "52oHbqMt2sh6"
   },
   "source": [
    "### Model Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xjQkkm342sh8"
   },
   "outputs": [],
   "source": [
    "def bunch_nonimage_features(df, colheaders, batch_size):\n",
    "    '''\n",
    "    Creates a batch with (hopefully) the same batches as the \n",
    "    train_generator, to hold nonimage features from the dataframe\n",
    "\n",
    "    The desired shape will be:\n",
    "    array - shape numbatches\n",
    "    array[0] - the number of columns of data\n",
    "    array[0][0] - data for the first column (one piece of data for each member of the batch)\n",
    "    so the shape would be:\n",
    "    (numbatches, numfeatures, batch_size)\n",
    "\n",
    "    Because this is a numpy array, all features must be numeric.\n",
    "    '''\n",
    "\n",
    "    for feat in colheaders:\n",
    "        assert df[feat].dtype in ['int', 'int8', 'int64'], f'Features must be numeric. {feat} is type {df[feat].dtype}'\n",
    "\n",
    "    #use ceiling because we need extras\n",
    "    numbatches = math.ceil(len(df) / batch_size)\n",
    "    numfeatures = len(colheaders)\n",
    "\n",
    "    #making an empty array to fill in with the information of the batches\n",
    "    feats_generator = np.zeros( (numbatches, numfeatures, batch_size) )\n",
    "\n",
    "    #using a for loop but I wonder if there's a way to do it better?\n",
    "    for i in range(numbatches):\n",
    "        startindex = i * batch_size\n",
    "\n",
    "        #if the data doesn't fit evenly into the bunches, manually insert it\n",
    "        if startindex + batch_size > len(df):\n",
    "            numleftover = startindex + batch_size - len(df) - 1\n",
    "            for counter, feat in enumerate(colheaders):\n",
    "                for j in range(0, numleftover):\n",
    "                    feats_generator[i][counter][j] = df[feat].iloc[startindex + j]\n",
    "\n",
    "        else:\n",
    "            stopindex = startindex + batch_size\n",
    "            for counter, feat in enumerate(colheaders):\n",
    "                feats_generator[i][counter] = df[feat].iloc[startindex:stopindex].values\n",
    "\n",
    "    print(f'Collected {numfeatures} feature(s) for {len(df)} images.')\n",
    "    return feats_generator\n",
    "\n",
    "\n",
    "def create_generators(df, datagen, path_col_header, feat_col_headers, target_header, batch_size, \n",
    "                      image_size= (256,256), color_mode = 'grayscale', class_mode = 'binary', SEED=None ):\n",
    "    '''\n",
    "    Takes in the things that we use for making a flow_from_dataframe generator, plus makes a feature array\n",
    "    for non-image features.\n",
    "    '''\n",
    "    if SEED == None:\n",
    "        #generate a random seed that will be constant\n",
    "        SEED = np.random.randint(0,100)\n",
    "\n",
    "    #sampling all of it gets a shuffled dataframe\n",
    "    df_shuffled = df.sample(frac=1, random_state = SEED)\n",
    "\n",
    "    #we need the length to perfectly fit the batch size so we're cutting off the extras \n",
    "    #sorry if this is bad practice\n",
    "    numbatches = math.ceil(len(df_shuffled) // batch_size)\n",
    "    corrected_length = numbatches * batch_size\n",
    "    df_shuffled = df_shuffled.iloc[0:corrected_length]\n",
    "\n",
    "    print(f'{len(df) - corrected_length} samples were removed.')\n",
    "\n",
    "    #get the features before we change the type to string\n",
    "    feats_gen = bunch_nonimage_features(df_shuffled, feat_col_headers, batch_size)\n",
    "    \n",
    "    #then change the types to strings because the flow_from_dataframe needs them to be strings\n",
    "    if type(target_header) == list:\n",
    "        for targ in target_header:\n",
    "            df_shuffled[targ] = df_shuffled[targ].apply(str)\n",
    "    else:\n",
    "        df_shuffled[target_header] = df_shuffled[target_header].apply(str)\n",
    "\n",
    "    train_generator = datagen.flow_from_dataframe(\n",
    "        df_shuffled, \n",
    "        x_col = path_col_header, \n",
    "        y_col = target_header, \n",
    "        target_size= image_size, \n",
    "        color_mode= color_mode, \n",
    "        class_mode= class_mode, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False,\n",
    "        seed=SEED, \n",
    "    )\n",
    "\n",
    "    print( f'{numbatches} batches created' )\n",
    "\n",
    "    return (train_generator, feats_gen)\n",
    "\n",
    "def make_iterator(image_generator, feature_generator):\n",
    "    '''\n",
    "    Used to properly use the image and feature generators with the custom non-image feature models\n",
    "    '''\n",
    "    #first make a feature generator for my feature array\n",
    "    feat_gen = (\n",
    "        feature_generator[i]\n",
    "        for i in range(len(feature_generator))\n",
    "    )\n",
    "    \n",
    "    feat_gen_rep = itertools.cycle(feat_gen)\n",
    "    image_gen_rep = itertools.cycle(image_generator)\n",
    "    \n",
    "    while True:\n",
    "      imgnext = next(image_gen_rep)\n",
    "      feats = next(feat_gen_rep)\n",
    "      yield [ imgnext[0], feats[0] ], imgnext[1]  #Yield the image, the features, and the labels (from features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aElsa64i2siD"
   },
   "source": [
    "### To create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xcb89tCW2siF"
   },
   "outputs": [],
   "source": [
    "def model_with_nonimage_features(im_shape, feats_shape):\n",
    "    '''\n",
    "    This model takes in the image data and the feature data.\n",
    "    '''\n",
    "    #create the inputs\n",
    "    img_input = Input(shape=im_shape, name='images')\n",
    "    feat_input = Input(shape=feats_shape, name='xtrafeatures')\n",
    "\n",
    "    #create the layers\n",
    "    #the image layers\n",
    "    x = Conv2D(32, kernel_size=3, activation='relu', padding='same', input_shape=im_shape) (img_input)\n",
    "    x = MaxPool2D() (x)\n",
    "    x = Conv2D(48, kernel_size=3, activation='relu',padding='same',) (x)\n",
    "    x = MaxPool2D() (x)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    #the other features layer\n",
    "    y = Dense(16, activation='relu')( feat_input )\n",
    "\n",
    "    #add the image and the features together and have another layer on top\n",
    "    added = Concatenate(axis=-1)([x, y])\n",
    "    z = Dense(8, activation='relu') (added)\n",
    "\n",
    "    #the final layer\n",
    "    predictions = Dense(2, activation='softmax')(z)\n",
    "\n",
    "    #create the model and return it\n",
    "    return Model(inputs=[img_input, feat_input], outputs=predictions)\n",
    "\n",
    "#model = model_with_nonimage_features( (image_size, image_size, 1) , (1,) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fcZRAr3a2siS"
   },
   "outputs": [],
   "source": [
    "def get_im_feat_gen(train_df):\n",
    "  nonimg_feats = ['Age', 'Sex', 'Image Type']\n",
    "  \n",
    "  #convert non-image features to numeric features :)\n",
    "  train_df['Sex'] = train_df['Sex'].astype('category').cat.codes\n",
    "  train_df['Image Type'] = train_df['Image Type'].astype('category').cat.codes\n",
    "\n",
    "  #load the data for the model\n",
    "  imgen, featgen = create_generators(\n",
    "      train_df,\n",
    "      datagen = ImageDataGenerator(rescale=1./255),\n",
    "      path_col_header = 'Path',\n",
    "      feat_col_headers = nonimg_feats,\n",
    "      target_header = 'No Finding',\n",
    "      batch_size = train_batch_size,\n",
    "      class_mode = 'binary', \n",
    "      SEED = SEED\n",
    "  )\n",
    "  \n",
    "  return (imgen, featgen)\n",
    "\n",
    "#myiterator = make_iterator(imgen, featgen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7zjIdiEC2sia"
   },
   "source": [
    "### To load a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20152,
     "status": "ok",
     "timestamp": 1564416038867,
     "user": {
      "displayName": "Gabi Muir",
      "photoUrl": "",
      "userId": "11169522930486928965"
     },
     "user_tz": 240
    },
    "id": "ahxeeD0n2sib",
    "outputId": "c1460ce2-66b5-4db8-aef6-551a8832f21b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0729 16:00:18.788795 140001614202752 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0729 16:00:38.624924 140001614202752 hdf5_format.py:221] No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model_import_name = 'DenseNet121_image_size_224'\n",
    "with CustomObjectScope({'GlorotUniform': glorot_uniform()}):\n",
    "        model = load_model(model_import_name+'.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "THQDGwBW2sig"
   },
   "source": [
    "### Compile the model\n",
    "\n",
    "(all models need to be compiled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 683,
     "status": "ok",
     "timestamp": 1564416043264,
     "user": {
      "displayName": "Gabi Muir",
      "photoUrl": "",
      "userId": "11169522930486928965"
     },
     "user_tz": 240
    },
    "id": "8-mnUcv-2sii",
    "outputId": "a839fb85-5471-4c6d-fe61-0eca165fbb07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"densenet121\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPadding2 (None, 230, 230, 3)  0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, 112, 112, 64) 9408        zero_padding2d_11[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1/relu (Activation)         (None, 112, 112, 64) 0           conv1/bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPadding2 (None, 114, 114, 64) 0           conv1/relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 56, 56, 64)   0           zero_padding2d_12[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 64)   256         pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, 56, 56, 64)   0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 128)  8192        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 128)  0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, 56, 56, 96)   0           pool1[0][0]                      \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, 56, 56, 96)   384         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, 56, 56, 96)   0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 128)  12288       conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 128)  0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, 56, 56, 128)  0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation (None, 56, 56, 128)  0           conv2_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 128)  16384       conv2_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 128)  0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenat (None, 56, 56, 160)  0           conv2_block2_concat[0][0]        \n",
      "                                                                 conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormali (None, 56, 56, 160)  640         conv2_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation (None, 56, 56, 160)  0           conv2_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)    (None, 56, 56, 128)  20480       conv2_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_relu (Activation (None, 56, 56, 128)  0           conv2_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenat (None, 56, 56, 192)  0           conv2_block3_concat[0][0]        \n",
      "                                                                 conv2_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormali (None, 56, 56, 192)  768         conv2_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation (None, 56, 56, 192)  0           conv2_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)    (None, 56, 56, 128)  24576       conv2_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_relu (Activation (None, 56, 56, 128)  0           conv2_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenat (None, 56, 56, 224)  0           conv2_block4_concat[0][0]        \n",
      "                                                                 conv2_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormali (None, 56, 56, 224)  896         conv2_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation (None, 56, 56, 224)  0           conv2_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)    (None, 56, 56, 128)  28672       conv2_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_relu (Activation (None, 56, 56, 128)  0           conv2_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenat (None, 56, 56, 256)  0           conv2_block5_concat[0][0]        \n",
      "                                                                 conv2_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, 56, 56, 256)  1024        conv2_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_relu (Activation)         (None, 56, 56, 256)  0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 56, 56, 128)  32768       pool2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)   (None, 28, 28, 128)  0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 128)  512         pool2_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation (None, 28, 28, 128)  0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  16384       conv3_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenat (None, 28, 28, 160)  0           pool2_pool[0][0]                 \n",
      "                                                                 conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormali (None, 28, 28, 160)  640         conv3_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation (None, 28, 28, 160)  0           conv3_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  20480       conv3_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenat (None, 28, 28, 192)  0           conv3_block1_concat[0][0]        \n",
      "                                                                 conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormali (None, 28, 28, 192)  768         conv3_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation (None, 28, 28, 192)  0           conv3_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  24576       conv3_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenat (None, 28, 28, 224)  0           conv3_block2_concat[0][0]        \n",
      "                                                                 conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormali (None, 28, 28, 224)  896         conv3_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation (None, 28, 28, 224)  0           conv3_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  28672       conv3_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenat (None, 28, 28, 256)  0           conv3_block3_concat[0][0]        \n",
      "                                                                 conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormali (None, 28, 28, 256)  1024        conv3_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation (None, 28, 28, 256)  0           conv3_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 28, 28, 128)  32768       conv3_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 28, 28, 128)  0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenat (None, 28, 28, 288)  0           conv3_block4_concat[0][0]        \n",
      "                                                                 conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormali (None, 28, 28, 288)  1152        conv3_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation (None, 28, 28, 288)  0           conv3_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 28, 28, 128)  36864       conv3_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 28, 28, 128)  0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenat (None, 28, 28, 320)  0           conv3_block5_concat[0][0]        \n",
      "                                                                 conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormali (None, 28, 28, 320)  1280        conv3_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation (None, 28, 28, 320)  0           conv3_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 28, 28, 128)  40960       conv3_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 28, 28, 128)  0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenat (None, 28, 28, 352)  0           conv3_block6_concat[0][0]        \n",
      "                                                                 conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormali (None, 28, 28, 352)  1408        conv3_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation (None, 28, 28, 352)  0           conv3_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 28, 28, 128)  45056       conv3_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 28, 28, 128)  0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenat (None, 28, 28, 384)  0           conv3_block7_concat[0][0]        \n",
      "                                                                 conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_bn (BatchNormali (None, 28, 28, 384)  1536        conv3_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_relu (Activation (None, 28, 28, 384)  0           conv3_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)    (None, 28, 28, 128)  49152       conv3_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_relu (Activation (None, 28, 28, 128)  0           conv3_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenat (None, 28, 28, 416)  0           conv3_block8_concat[0][0]        \n",
      "                                                                 conv3_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_bn (BatchNormal (None, 28, 28, 416)  1664        conv3_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_relu (Activatio (None, 28, 28, 416)  0           conv3_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)   (None, 28, 28, 128)  53248       conv3_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatena (None, 28, 28, 448)  0           conv3_block9_concat[0][0]        \n",
      "                                                                 conv3_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_bn (BatchNormal (None, 28, 28, 448)  1792        conv3_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_relu (Activatio (None, 28, 28, 448)  0           conv3_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)   (None, 28, 28, 128)  57344       conv3_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatena (None, 28, 28, 480)  0           conv3_block10_concat[0][0]       \n",
      "                                                                 conv3_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_bn (BatchNormal (None, 28, 28, 480)  1920        conv3_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_relu (Activatio (None, 28, 28, 480)  0           conv3_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)   (None, 28, 28, 128)  61440       conv3_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatena (None, 28, 28, 512)  0           conv3_block11_concat[0][0]       \n",
      "                                                                 conv3_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, 28, 28, 512)  2048        conv3_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_relu (Activation)         (None, 28, 28, 512)  0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 28, 28, 256)  131072      pool3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)   (None, 14, 14, 256)  0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 256)  1024        pool3_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation (None, 14, 14, 256)  0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 128)  32768       conv4_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 128)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenat (None, 14, 14, 288)  0           pool3_pool[0][0]                 \n",
      "                                                                 conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormali (None, 14, 14, 288)  1152        conv4_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation (None, 14, 14, 288)  0           conv4_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 128)  36864       conv4_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 128)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenat (None, 14, 14, 320)  0           conv4_block1_concat[0][0]        \n",
      "                                                                 conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormali (None, 14, 14, 320)  1280        conv4_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation (None, 14, 14, 320)  0           conv4_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 128)  40960       conv4_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 128)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenat (None, 14, 14, 352)  0           conv4_block2_concat[0][0]        \n",
      "                                                                 conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormali (None, 14, 14, 352)  1408        conv4_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation (None, 14, 14, 352)  0           conv4_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 128)  45056       conv4_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 128)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenat (None, 14, 14, 384)  0           conv4_block3_concat[0][0]        \n",
      "                                                                 conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormali (None, 14, 14, 384)  1536        conv4_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation (None, 14, 14, 384)  0           conv4_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 128)  49152       conv4_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 128)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenat (None, 14, 14, 416)  0           conv4_block4_concat[0][0]        \n",
      "                                                                 conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormali (None, 14, 14, 416)  1664        conv4_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation (None, 14, 14, 416)  0           conv4_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 128)  53248       conv4_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 128)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenat (None, 14, 14, 448)  0           conv4_block5_concat[0][0]        \n",
      "                                                                 conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormali (None, 14, 14, 448)  1792        conv4_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation (None, 14, 14, 448)  0           conv4_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 14, 14, 128)  57344       conv4_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 14, 14, 128)  0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenat (None, 14, 14, 480)  0           conv4_block6_concat[0][0]        \n",
      "                                                                 conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormali (None, 14, 14, 480)  1920        conv4_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_relu (Activation (None, 14, 14, 480)  0           conv4_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 14, 14, 128)  61440       conv4_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 14, 14, 128)  0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenat (None, 14, 14, 512)  0           conv4_block7_concat[0][0]        \n",
      "                                                                 conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_relu (Activation (None, 14, 14, 512)  0           conv4_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 14, 14, 128)  65536       conv4_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 14, 14, 128)  0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenat (None, 14, 14, 544)  0           conv4_block8_concat[0][0]        \n",
      "                                                                 conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_bn (BatchNormal (None, 14, 14, 544)  2176        conv4_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_relu (Activatio (None, 14, 14, 544)  0           conv4_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 14, 14, 128)  69632       conv4_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatena (None, 14, 14, 576)  0           conv4_block9_concat[0][0]        \n",
      "                                                                 conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_bn (BatchNormal (None, 14, 14, 576)  2304        conv4_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_relu (Activatio (None, 14, 14, 576)  0           conv4_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 14, 14, 128)  73728       conv4_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatena (None, 14, 14, 608)  0           conv4_block10_concat[0][0]       \n",
      "                                                                 conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_bn (BatchNormal (None, 14, 14, 608)  2432        conv4_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_relu (Activatio (None, 14, 14, 608)  0           conv4_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 14, 14, 128)  77824       conv4_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatena (None, 14, 14, 640)  0           conv4_block11_concat[0][0]       \n",
      "                                                                 conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_bn (BatchNormal (None, 14, 14, 640)  2560        conv4_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_relu (Activatio (None, 14, 14, 640)  0           conv4_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 14, 14, 128)  81920       conv4_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatena (None, 14, 14, 672)  0           conv4_block12_concat[0][0]       \n",
      "                                                                 conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_bn (BatchNormal (None, 14, 14, 672)  2688        conv4_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_relu (Activatio (None, 14, 14, 672)  0           conv4_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 14, 14, 128)  86016       conv4_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatena (None, 14, 14, 704)  0           conv4_block13_concat[0][0]       \n",
      "                                                                 conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_bn (BatchNormal (None, 14, 14, 704)  2816        conv4_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_relu (Activatio (None, 14, 14, 704)  0           conv4_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 14, 14, 128)  90112       conv4_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatena (None, 14, 14, 736)  0           conv4_block14_concat[0][0]       \n",
      "                                                                 conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_bn (BatchNormal (None, 14, 14, 736)  2944        conv4_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_relu (Activatio (None, 14, 14, 736)  0           conv4_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 14, 14, 128)  94208       conv4_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatena (None, 14, 14, 768)  0           conv4_block15_concat[0][0]       \n",
      "                                                                 conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_bn (BatchNormal (None, 14, 14, 768)  3072        conv4_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_relu (Activatio (None, 14, 14, 768)  0           conv4_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 14, 14, 128)  98304       conv4_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_concat (Concatena (None, 14, 14, 800)  0           conv4_block16_concat[0][0]       \n",
      "                                                                 conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_bn (BatchNormal (None, 14, 14, 800)  3200        conv4_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_relu (Activatio (None, 14, 14, 800)  0           conv4_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 14, 14, 128)  102400      conv4_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_concat (Concatena (None, 14, 14, 832)  0           conv4_block17_concat[0][0]       \n",
      "                                                                 conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_bn (BatchNormal (None, 14, 14, 832)  3328        conv4_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_relu (Activatio (None, 14, 14, 832)  0           conv4_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 14, 14, 128)  106496      conv4_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_concat (Concatena (None, 14, 14, 864)  0           conv4_block18_concat[0][0]       \n",
      "                                                                 conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_bn (BatchNormal (None, 14, 14, 864)  3456        conv4_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_relu (Activatio (None, 14, 14, 864)  0           conv4_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 14, 14, 128)  110592      conv4_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_concat (Concatena (None, 14, 14, 896)  0           conv4_block19_concat[0][0]       \n",
      "                                                                 conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_bn (BatchNormal (None, 14, 14, 896)  3584        conv4_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_relu (Activatio (None, 14, 14, 896)  0           conv4_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 14, 14, 128)  114688      conv4_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_concat (Concatena (None, 14, 14, 928)  0           conv4_block20_concat[0][0]       \n",
      "                                                                 conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_bn (BatchNormal (None, 14, 14, 928)  3712        conv4_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_relu (Activatio (None, 14, 14, 928)  0           conv4_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 14, 14, 128)  118784      conv4_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_concat (Concatena (None, 14, 14, 960)  0           conv4_block21_concat[0][0]       \n",
      "                                                                 conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_bn (BatchNormal (None, 14, 14, 960)  3840        conv4_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_relu (Activatio (None, 14, 14, 960)  0           conv4_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 14, 14, 128)  122880      conv4_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_concat (Concatena (None, 14, 14, 992)  0           conv4_block22_concat[0][0]       \n",
      "                                                                 conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_bn (BatchNormal (None, 14, 14, 992)  3968        conv4_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_relu (Activatio (None, 14, 14, 992)  0           conv4_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 14, 14, 128)  126976      conv4_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_concat (Concatena (None, 14, 14, 1024) 0           conv4_block23_concat[0][0]       \n",
      "                                                                 conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalization)   (None, 14, 14, 1024) 4096        conv4_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_relu (Activation)         (None, 14, 14, 1024) 0           pool4_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)             (None, 14, 14, 512)  524288      pool4_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)   (None, 7, 7, 512)    0           pool4_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 512)    2048        pool4_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation (None, 7, 7, 512)    0           conv5_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 128)    65536       conv5_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 128)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_concat (Concatenat (None, 7, 7, 544)    0           pool4_pool[0][0]                 \n",
      "                                                                 conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_bn (BatchNormali (None, 7, 7, 544)    2176        conv5_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_relu (Activation (None, 7, 7, 544)    0           conv5_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 128)    69632       conv5_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 128)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_concat (Concatenat (None, 7, 7, 576)    0           conv5_block1_concat[0][0]        \n",
      "                                                                 conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_bn (BatchNormali (None, 7, 7, 576)    2304        conv5_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_relu (Activation (None, 7, 7, 576)    0           conv5_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 128)    73728       conv5_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 128)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_concat (Concatenat (None, 7, 7, 608)    0           conv5_block2_concat[0][0]        \n",
      "                                                                 conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_bn (BatchNormali (None, 7, 7, 608)    2432        conv5_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_relu (Activation (None, 7, 7, 608)    0           conv5_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_conv (Conv2D)    (None, 7, 7, 128)    77824       conv5_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_relu (Activation (None, 7, 7, 128)    0           conv5_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_concat (Concatenat (None, 7, 7, 640)    0           conv5_block3_concat[0][0]        \n",
      "                                                                 conv5_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_bn (BatchNormali (None, 7, 7, 640)    2560        conv5_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_relu (Activation (None, 7, 7, 640)    0           conv5_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_conv (Conv2D)    (None, 7, 7, 128)    81920       conv5_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_relu (Activation (None, 7, 7, 128)    0           conv5_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_concat (Concatenat (None, 7, 7, 672)    0           conv5_block4_concat[0][0]        \n",
      "                                                                 conv5_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_bn (BatchNormali (None, 7, 7, 672)    2688        conv5_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_relu (Activation (None, 7, 7, 672)    0           conv5_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_conv (Conv2D)    (None, 7, 7, 128)    86016       conv5_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_relu (Activation (None, 7, 7, 128)    0           conv5_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_concat (Concatenat (None, 7, 7, 704)    0           conv5_block5_concat[0][0]        \n",
      "                                                                 conv5_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_bn (BatchNormali (None, 7, 7, 704)    2816        conv5_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_relu (Activation (None, 7, 7, 704)    0           conv5_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_conv (Conv2D)    (None, 7, 7, 128)    90112       conv5_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_relu (Activation (None, 7, 7, 128)    0           conv5_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_concat (Concatenat (None, 7, 7, 736)    0           conv5_block6_concat[0][0]        \n",
      "                                                                 conv5_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_bn (BatchNormali (None, 7, 7, 736)    2944        conv5_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_relu (Activation (None, 7, 7, 736)    0           conv5_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_conv (Conv2D)    (None, 7, 7, 128)    94208       conv5_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_relu (Activation (None, 7, 7, 128)    0           conv5_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_concat (Concatenat (None, 7, 7, 768)    0           conv5_block7_concat[0][0]        \n",
      "                                                                 conv5_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_bn (BatchNormali (None, 7, 7, 768)    3072        conv5_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_relu (Activation (None, 7, 7, 768)    0           conv5_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_conv (Conv2D)    (None, 7, 7, 128)    98304       conv5_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_relu (Activation (None, 7, 7, 128)    0           conv5_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_concat (Concatenat (None, 7, 7, 800)    0           conv5_block8_concat[0][0]        \n",
      "                                                                 conv5_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_bn (BatchNormal (None, 7, 7, 800)    3200        conv5_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_relu (Activatio (None, 7, 7, 800)    0           conv5_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_conv (Conv2D)   (None, 7, 7, 128)    102400      conv5_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_concat (Concatena (None, 7, 7, 832)    0           conv5_block9_concat[0][0]        \n",
      "                                                                 conv5_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_bn (BatchNormal (None, 7, 7, 832)    3328        conv5_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_relu (Activatio (None, 7, 7, 832)    0           conv5_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_conv (Conv2D)   (None, 7, 7, 128)    106496      conv5_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_concat (Concatena (None, 7, 7, 864)    0           conv5_block10_concat[0][0]       \n",
      "                                                                 conv5_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_bn (BatchNormal (None, 7, 7, 864)    3456        conv5_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_relu (Activatio (None, 7, 7, 864)    0           conv5_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_conv (Conv2D)   (None, 7, 7, 128)    110592      conv5_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_concat (Concatena (None, 7, 7, 896)    0           conv5_block11_concat[0][0]       \n",
      "                                                                 conv5_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_bn (BatchNormal (None, 7, 7, 896)    3584        conv5_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_relu (Activatio (None, 7, 7, 896)    0           conv5_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_conv (Conv2D)   (None, 7, 7, 128)    114688      conv5_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_concat (Concatena (None, 7, 7, 928)    0           conv5_block12_concat[0][0]       \n",
      "                                                                 conv5_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_bn (BatchNormal (None, 7, 7, 928)    3712        conv5_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_relu (Activatio (None, 7, 7, 928)    0           conv5_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_conv (Conv2D)   (None, 7, 7, 128)    118784      conv5_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_concat (Concatena (None, 7, 7, 960)    0           conv5_block13_concat[0][0]       \n",
      "                                                                 conv5_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_bn (BatchNormal (None, 7, 7, 960)    3840        conv5_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_relu (Activatio (None, 7, 7, 960)    0           conv5_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_conv (Conv2D)   (None, 7, 7, 128)    122880      conv5_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_concat (Concatena (None, 7, 7, 992)    0           conv5_block14_concat[0][0]       \n",
      "                                                                 conv5_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_bn (BatchNormal (None, 7, 7, 992)    3968        conv5_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_relu (Activatio (None, 7, 7, 992)    0           conv5_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_conv (Conv2D)   (None, 7, 7, 128)    126976      conv5_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_concat (Concatena (None, 7, 7, 1024)   0           conv5_block15_concat[0][0]       \n",
      "                                                                 conv5_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 7, 7, 1024)   4096        conv5_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "relu (Activation)               (None, 7, 7, 1024)   0           bn[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 1024)         0           relu[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "fc1000 (Dense)                  (None, 1000)         1025000     avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 8,062,504\n",
      "Trainable params: 7,978,856\n",
      "Non-trainable params: 83,648\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "  loss='sparse_categorical_crossentropy',\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate = lr),\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gLhs7btS2sip"
   },
   "source": [
    "### Save the model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MOaK-e1I2siq",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(model_directory + 'model_summary.txt', 'w') as f:\n",
    "    with redirect_stdout(f):\n",
    "        model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M5JikHvG2siw"
   },
   "source": [
    "### Setup Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F-14Atci2siy"
   },
   "outputs": [],
   "source": [
    "checkpoints_path = model_directory + \"checkpoints/\"+model_name+\"checkpoint-epoch{epoch:02d}-acc{acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(checkpoints_path,  \n",
    "                             monitor = 'acc',\n",
    "                             verbose=0, \n",
    "                             save_best_only=False, \n",
    "                             save_weights_only=False, \n",
    "                             mode='auto'\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lx8wklqj2si1"
   },
   "source": [
    "## Run the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XmKCZSISp49F"
   },
   "source": [
    "\n",
    "### Train the model\n",
    "\n",
    "(only necessary when you are creating a model, not loading a model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1417286,
     "status": "ok",
     "timestamp": 1564425432971,
     "user": {
      "displayName": "Gabi Muir",
      "photoUrl": "",
      "userId": "11169522930486928965"
     },
     "user_tz": 240
    },
    "id": "IE25hH7I2si2",
    "outputId": "b3d4d6c4-cd20-45e1-c51c-998165c35b0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "There are 111178 patients with Lung Opacity, compared to 112232 patients in the dataset without Lung Opacity\n",
      "49.76411082762634% of patients have Lung Opacity\n",
      "1054 (0.9391260959441158%) of patients without Lung Opacity will be randomly removed from the sample pool\n",
      "training set: (100000, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Frontal/Lateral</th>\n",
       "      <th>AP/PA</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Support Devices</th>\n",
       "      <th>Image Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91369</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient21908/study3/...</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>PA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185967</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient44151/study4/...</td>\n",
       "      <td>Female</td>\n",
       "      <td>20</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119090</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient28539/study6/...</td>\n",
       "      <td>Male</td>\n",
       "      <td>79</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Path  ... Image Type\n",
       "91369   CheXpert-v1.0-small/train/patient21908/study3/...  ...         PA\n",
       "185967  CheXpert-v1.0-small/train/patient44151/study4/...  ...         AP\n",
       "119090  CheXpert-v1.0-small/train/patient28539/study6/...  ...         AP\n",
       "\n",
       "[3 rows x 20 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 samples were removed.\n",
      "Collected 3 feature(s) for 100000 images.\n",
      "Found 100000 validated image filenames belonging to 2 classes.\n",
      "3125 batches created\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3149 - acc: 0.8950\n",
      "Epoch 2\n",
      "200/200 [==============================] - 26s 130ms/step - loss: 0.2893 - acc: 0.9041\n",
      "Epoch 3\n",
      "200/200 [==============================] - 28s 139ms/step - loss: 0.3025 - acc: 0.8945\n",
      "Epoch 4\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.2786 - acc: 0.9011\n",
      "Epoch 5\n",
      "200/200 [==============================] - 32s 162ms/step - loss: 0.2878 - acc: 0.8994\n",
      "Epoch 6\n",
      "200/200 [==============================] - 34s 171ms/step - loss: 0.2844 - acc: 0.9003\n",
      "Epoch 7\n",
      "200/200 [==============================] - 31s 156ms/step - loss: 0.2777 - acc: 0.8998\n",
      "Epoch 8\n",
      "200/200 [==============================] - 27s 137ms/step - loss: 0.2708 - acc: 0.9064\n",
      "Epoch 9\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 0.2761 - acc: 0.8997\n",
      "Epoch 10\n",
      "200/200 [==============================] - 24s 120ms/step - loss: 0.2636 - acc: 0.9048\n",
      "Epoch 11\n",
      "200/200 [==============================] - 27s 135ms/step - loss: 0.2820 - acc: 0.9002\n",
      "Epoch 12\n",
      "200/200 [==============================] - 30s 152ms/step - loss: 0.2882 - acc: 0.8967\n",
      "Epoch 13\n",
      "200/200 [==============================] - 34s 170ms/step - loss: 0.2727 - acc: 0.9058\n",
      "Epoch 14\n",
      "200/200 [==============================] - 32s 162ms/step - loss: 0.2775 - acc: 0.8991\n",
      "Epoch 15\n",
      "200/200 [==============================] - 29s 147ms/step - loss: 0.2812 - acc: 0.8989\n",
      "Epoch 16\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.2751 - acc: 0.8966\n",
      "Epoch 17\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 0.2681 - acc: 0.9042\n",
      "Epoch 18\n",
      "200/200 [==============================] - 21s 107ms/step - loss: 0.2885 - acc: 0.8939\n",
      "Epoch 19\n",
      "200/200 [==============================] - 24s 121ms/step - loss: 0.2630 - acc: 0.9014\n",
      "Epoch 20\n",
      "200/200 [==============================] - 28s 139ms/step - loss: 0.2796 - acc: 0.8997\n",
      "Epoch 21\n",
      "200/200 [==============================] - 31s 156ms/step - loss: 0.2809 - acc: 0.8984\n",
      "Epoch 22\n",
      "200/200 [==============================] - 35s 173ms/step - loss: 0.2703 - acc: 0.9009\n",
      "Epoch 23\n",
      "200/200 [==============================] - 31s 156ms/step - loss: 0.2674 - acc: 0.9058\n",
      "Epoch 24\n",
      "200/200 [==============================] - 27s 137ms/step - loss: 0.2714 - acc: 0.8994\n",
      "Epoch 25\n",
      "200/200 [==============================] - 23s 117ms/step - loss: 0.2604 - acc: 0.9041\n",
      "Epoch 26\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.2763 - acc: 0.9006\n",
      "Epoch 27\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.2810 - acc: 0.8973\n",
      "Epoch 28\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.2685 - acc: 0.9052\n",
      "Epoch 29\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 0.2751 - acc: 0.8983\n",
      "Epoch 30\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.2708 - acc: 0.9016\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def run_the_model():\n",
    "  '''\n",
    "  This custom model has some sort of memory leak (?) so it uses up 12gb of RAM \n",
    "  by the 5th epoch. To prevent this, we are saving and loading the model one epoch\n",
    "  at a time.\n",
    "  '''\n",
    "  #create the model\n",
    "  model = model_with_nonimage_features( (image_size, image_size, 1) , (1,) )\n",
    "\n",
    "  #save the model summary\n",
    "  with open(model_directory + 'model_summary.txt', 'w') as f:\n",
    "    with redirect_stdout(f):\n",
    "      model.summary()\n",
    "\n",
    "  model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate = lr),\n",
    "    metrics=['accuracy']\n",
    "  )\n",
    "  \n",
    "  #run it once then save it\n",
    "  print('Epoch 1')\n",
    "  \n",
    "  train_df = get_train_df()\n",
    "  \n",
    "  imgen, featgen = get_im_feat_gen(train_df)\n",
    "  \n",
    "  model.fit_generator(\n",
    "      make_iterator( imgen, featgen ),\n",
    "      steps_per_epoch = num_steps_per_epoch, \n",
    "      epochs = 1,\n",
    "    )\n",
    "  model.save(model_directory+'/checkpoints/epoch'+str(0)+'save.h5')\n",
    "\n",
    "  #delete the model to save space in RAM\n",
    "  del model\n",
    "  gc.collect()\n",
    "\n",
    "  # run it for each epoch\n",
    "  for epoch in range(num_epochs-1):\n",
    "    print('Epoch', epoch+2)\n",
    "    model = load_model( model_directory+'/checkpoints/epoch'+str(epoch)+'save.h5' )\n",
    "    model.fit_generator(\n",
    "      make_iterator( imgen, featgen ),\n",
    "      steps_per_epoch = num_steps_per_epoch, \n",
    "      epochs = 1,\n",
    "    )\n",
    "    model.save(model_directory+'/checkpoints/epoch'+str(epoch+1)+'save.h5')\n",
    "    del model\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "run_the_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VCsrHL-M2si8"
   },
   "source": [
    "### Make Predictions\n",
    "\n",
    "(be patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VpgOCIZy2si-"
   },
   "outputs": [],
   "source": [
    "def get_test_im_feat_gen(test_df):\n",
    "  '''\n",
    "  Prepares the testing dataframe generators since the tester has different\n",
    "  variables than the training set.\n",
    "  '''\n",
    "  nonimg_feats = ['Age', 'Sex', 'Image Type']\n",
    "  \n",
    "  #convert non-image features to numeric features :)\n",
    "  test_df['Sex'] = test_df['Sex'].astype('category').cat.codes\n",
    "  test_df['Image Type'] = test_df['Image Type'].astype('category').cat.codes\n",
    "\n",
    "  #load the data for the model\n",
    "  imgen, featgen = create_generators(\n",
    "      test_df,\n",
    "      datagen = ImageDataGenerator(rescale=1./255),\n",
    "      path_col_header = 'Path',\n",
    "      feat_col_headers = nonimg_feats,\n",
    "      target_header = 'No Finding',\n",
    "      batch_size = test_batch_size,\n",
    "      class_mode = 'binary'\n",
    "  )\n",
    "  return (imgen, featgen)\n",
    "\n",
    "def make_non_cycling_iterator(image_generator, feature_generator):\n",
    "  '''\n",
    "  Used to properly use the image and feature generators with the custom non-image feature models.\n",
    "  This one is used for the test set, since it leaks memory when it cycles (?)\n",
    "  '''\n",
    "  #first make a feature generator for my feature array\n",
    "  feat_gen = (\n",
    "      feature_generator[i]\n",
    "      for i in range(len(feature_generator))\n",
    "  )\n",
    "  \n",
    "  while True:\n",
    "    imgnext = next(image_generator)\n",
    "    feats = next(feat_gen)\n",
    "    yield [ imgnext[0], feats[0] ], imgnext[1]  #Yield the image, the features, and the labels (from features)\n",
    "\n",
    "\n",
    "def make_predictions():\n",
    "  test_df = get_test_df()\n",
    "  \n",
    "  model = load_model( model_directory+'/checkpoints/epoch'+str(num_epochs-1)+'save.h5' )\n",
    "\n",
    "  imgen, featgen = get_test_im_feat_gen(test_df)\n",
    "  \n",
    "  predictions = model.predict_generator(make_non_cycling_iterator( imgen, featgen ), \n",
    "                                        steps = test_batch_size)\n",
    "  print(f'made {len(predictions)} predictions')\n",
    "  \n",
    "  # This checks the row that is related to 'being sick' (... hopefully)\n",
    "  probability_sick = predictions.T[1]\n",
    "  print('predictions:', probability_sick[0:10])\n",
    "  actual_labels = imgen[0][1]\n",
    "  print('actual labels:',actual_labels[0:10])\n",
    "  \n",
    "  return (probability_sick, actual_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 213
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21595,
     "status": "ok",
     "timestamp": 1564425893361,
     "user": {
      "displayName": "Gabi Muir",
      "photoUrl": "",
      "userId": "11169522930486928965"
     },
     "user_tz": 240
    },
    "id": "HF2tBW88r3Hc",
    "outputId": "b2221188-2085-46e9-90cd-2d7012b7e346"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set: (234, 20)\n",
      "0 samples were removed.\n",
      "Collected 3 feature(s) for 234 images.\n",
      "Found 234 validated image filenames belonging to 2 classes.\n",
      "1 batches created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0729 18:44:52.818825 140320953005952 training_generator.py:251] Your dataset iterator ran out of data; interrupting training. Make sure that your iterator can generate at least `steps * epochs` batches (in this case, 234 batches). You may need touse the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "made 234 predictions\n",
      "predictions: [0.14837646 0.00691801 0.09738541 0.01180117 0.33872932 0.04494812\n",
      " 0.00484509 0.01307427 0.2982214  0.17281269]\n",
      "actual labels: [0. 0. 1. 0. 1. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "probability_sick, actual_labels = make_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uXcbzBV92sjK"
   },
   "source": [
    "### Save the Model\n",
    "(was already saved while running. the last epoch is the final model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2194,
     "status": "error",
     "timestamp": 1564149958268,
     "user": {
      "displayName": "Gabi Muir",
      "photoUrl": "",
      "userId": "11169522930486928965"
     },
     "user_tz": 240
    },
    "id": "c-E6pi742sjM",
    "outputId": "1f500ced-0961-4fef-d25c-1bab4e1d534b"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-4cfe3b21d4dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_directory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model saved in'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save(model_directory + model_name + '.h5')\n",
    "\n",
    "print('Model saved in', model_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vRALTv_o2sjR"
   },
   "source": [
    "## Do metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CFq--Jn52sjU"
   },
   "outputs": [],
   "source": [
    "def get_confusion_matrix(predictions, actuals, threshold):\n",
    "  \"\"\"\n",
    "  Returns a confusion matrix whose rows correspond to predicted outputs and\n",
    "      whose columns correspond to actual outputs.\n",
    "\n",
    "  predictions: 1D numpy array.\n",
    "  actuals: 1D numpy array.\n",
    "  threshold: float, value above which predictions are classified as positive,\n",
    "      below which predictions are classified as negative.\n",
    "  \"\"\"\n",
    "  bool_predictions = (predictions > threshold)\n",
    "  bool_actuals = (actuals > threshold)\n",
    "\n",
    "  return confusion_matrix(bool_predictions, bool_actuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A8GK4Dcs2sjX"
   },
   "outputs": [],
   "source": [
    "def get_metrics(predictions, actuals, threshold):\n",
    "  \"\"\"\n",
    "  Prints all metrics associated with the model output.\n",
    "\n",
    "  predictions: 1D numpy array.\n",
    "  actuals: 1D numpy array.\n",
    "  threshold: float, value above which predictions are classified as positive,\n",
    "      below which predictions are classified as negative.\n",
    "  \"\"\"\n",
    "  TP, FP, FN, TN = get_confusion_matrix(predictions, actuals, threshold).ravel()\n",
    "\n",
    "  trues = TP + TN\n",
    "  wrongs = FP + FN\n",
    "  sensitivity = TP / (TP + FN) # This is also recall\n",
    "  specificity = TN / (TN + FP)\n",
    "  precision = TP / (TP +FP)\n",
    "  accuracy = (TP + TN) / (TP + TN + FP +FN)\n",
    "  F1 = 2 / ((1 / precision) + (1 / sensitivity))\n",
    "  \n",
    "  metrics_df = pd.DataFrame()\n",
    "  metrics_df['Correct Predictions'] = [trues]\n",
    "  metrics_df['Incorrect Predictions'] = [wrongs]\n",
    "  metrics_df['Sensitivity'] = [sensitivity]\n",
    "  metrics_df['Specificity'] = [specificity]\n",
    "  metrics_df['Precision'] = [precision]\n",
    "  metrics_df['Accuracy'] = [accuracy]\n",
    "  metrics_df['F1 score'] = [F1]\n",
    "  metrics_df.index = [model_name]\n",
    "  metrics_df\n",
    "  t = metrics_df.transpose()\n",
    "  t.to_csv(model_directory+model_name+'metrics.csv')\n",
    "  display(t)\n",
    "  \n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3lI94CLw2sja"
   },
   "outputs": [],
   "source": [
    "def get_roc_curve(predictions, actuals):\n",
    "  \"\"\"\n",
    "  Plots the ROC curve and associated AUC of the model output.\n",
    "\n",
    "  predictions: 1D numpy array.\n",
    "  actuals: 1D numpy array.\n",
    "  \"\"\"\n",
    "  FPR, TPR, thresholds = roc_curve(actuals, predictions)\n",
    "  AUC = roc_auc_score(actuals, predictions)\n",
    "\n",
    "  plt.plot(FPR, TPR, \"b-\")\n",
    "  plt.plot([0, 1], [0, 1], \"r--\")\n",
    "  plt.title(\"Receiver Operating Characteristic \\n AUC: {}\".format(AUC))\n",
    "  plt.xlim([-0.05, 1.05])\n",
    "  plt.ylim([-0.05, 1.05])\n",
    "  plt.ylabel(\"Sensitivity\")\n",
    "  plt.xlabel(\"1 - Specificity\")\n",
    "  plt.savefig(model_directory+model_name+'ROC_curve.png')\n",
    "  plt.show()\n",
    "  \n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2YgnsV6h2sjd"
   },
   "outputs": [],
   "source": [
    "def get_precision_recall_curve(predictions, actuals):\n",
    "  \"\"\"\n",
    "  Plots the precision-recall curve and associated AUC of the model output.\n",
    "\n",
    "  predictions: 2D numpy array.\n",
    "  actuals: 1D numpy array.\n",
    "  \"\"\"\n",
    "  precisions, recalls, thresholds = precision_recall_curve(actuals, predictions)\n",
    "  AUC = auc(recalls, precisions)\n",
    "\n",
    "  plt.plot(recalls, precisions, \"b-\")\n",
    "  plt.plot([0, 1], [1, 0], \"r--\")\n",
    "  plt.title(\"Precision-Recall Curve \\n AUC: {}\".format(AUC))\n",
    "  plt.xlim([-0.05, 1.05])\n",
    "  plt.ylim([-0.05, 1.05])\n",
    "  plt.ylabel(\"Recall\")\n",
    "  plt.xlabel(\"Precision\")\n",
    "  plt.savefig(model_directory+model_name+'precision_recall_curve.png')\n",
    "  plt.show()\n",
    "  \n",
    "  return 'saved precision recall curve'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MkVBousN2sjj"
   },
   "outputs": [],
   "source": [
    "def display_conf_mat(predictions, actuals, threshold):\n",
    "  '''\n",
    "  Displays and saves the confusion matrix\n",
    "  '''\n",
    "  cm = get_confusion_matrix(predictions, actuals, threshold)\n",
    "  ax = plt.subplot()\n",
    "  sns.heatmap(cm, annot=True, ax = ax, cmap=plt.cm.Blues,fmt='g') #annot=True to annotate cells\n",
    "\n",
    "  # labels, title and ticks\n",
    "  ax.set_ylabel('Predicted labels')\n",
    "  ax.set_xlabel('True labels')\n",
    "  ax.set_title('Confusion Matrix')\n",
    "  plt.savefig(model_directory + model_name + 'confusion_matrix.png')\n",
    "  plt.show()\n",
    "  \n",
    "  return 'saved confusion matrix'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GsNKvL8S2sjo"
   },
   "source": [
    "## Run the Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1273,
     "status": "ok",
     "timestamp": 1564428220832,
     "user": {
      "displayName": "Gabi Muir",
      "photoUrl": "",
      "userId": "11169522930486928965"
     },
     "user_tz": 240
    },
    "id": "UwovOLPg2sjo",
    "outputId": "89521636-54bb-424f-8f38-83c0e3ea2a72"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>multimodel_lungopacity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Correct Predictions</th>\n",
       "      <td>196.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Incorrect Predictions</th>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sensitivity</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specificity</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.837607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.837607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 score</th>\n",
       "      <td>0.911628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       multimodel_lungopacity\n",
       "Correct Predictions                196.000000\n",
       "Incorrect Predictions               38.000000\n",
       "Sensitivity                          1.000000\n",
       "Specificity                          0.000000\n",
       "Precision                            0.837607\n",
       "Accuracy                             0.837607\n",
       "F1 score                             0.911628"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEcCAYAAADN+K/qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYsATEckUA56ISKYY8EREMvX/ABFnW+meZv5yAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAErCAYAAAAmFw8fAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAErCAYAAAAmFw8fAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'saved precision recall curve'"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics(probability_sick, actual_labels, threshold)\n",
    "display_conf_mat(probability_sick, actual_labels, threshold)\n",
    "get_roc_curve(probability_sick, actual_labels)\n",
    "get_precision_recall_curve(probability_sick, actual_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z8J3oys42sjv"
   },
   "source": [
    "## Prediction Visualization\n",
    "\n",
    "(doesn't work with our multi-model - maybe i'll fix it soon but eh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5XiEibuI2sjv"
   },
   "outputs": [],
   "source": [
    "def plot_image(i, probability_sick, actual_labels, images_bucket, threshold):\n",
    "    '''\n",
    "    Plots images next to labels, color coded based on if they were correct or not.\n",
    "    '''\n",
    "    prob_sick = probability_sick[i]\n",
    "    true_label = int(actual_labels[i])\n",
    "\n",
    "    # Remove grid, x and y axis ticks from the chart\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    # Plot the image\n",
    "    plt.imshow( images_bucket[i, :, :, 0], cmap='gray')\n",
    "\n",
    "    if prob_sick > threshold:\n",
    "        predicted_label = 1\n",
    "    else:\n",
    "        predicted_label = 0\n",
    "    \n",
    "    # Set color to blue on a correct prediction, otherwise set color to red\n",
    "    if predicted_label == true_label:\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'\n",
    "\n",
    "    class_names = ['Not '+target, target ]\n",
    "    # Print the predicted label, confidence number, and actual label\n",
    "    plot_label = f\"Predicted probability of {target} is {round(100*prob_sick, 2)}%, \" + \\\n",
    "            f\"\\n so we predict {class_names[predicted_label]} \" + \\\n",
    "            f\"\\n while true label is {class_names[true_label]}\"\n",
    "    plt.xlabel(plot_label,color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 343,
     "status": "error",
     "timestamp": 1564152177281,
     "user": {
      "displayName": "Gabi Muir",
      "photoUrl": "",
      "userId": "11169522930486928965"
     },
     "user_tz": 240
    },
    "id": "a8M14trX2sjy",
    "outputId": "0125dc33-188a-4b75-861a-ac5128b2d527"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-5ec86c083d10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots_adjust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mimages_bucket\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_generator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_generator' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1728x1152 with 0 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_rows = 4\n",
    "num_cols = 3\n",
    "num_images = num_rows*num_cols\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(4*2*num_cols, 4*num_rows))\n",
    "fig.subplots_adjust(hspace=.5)\n",
    "\n",
    "images_bucket = test_generator[0][0]\n",
    "\n",
    "for i in range(num_images):\n",
    "    print(f'Probability of sickness: {round(100* probability_sick[i], 2)}%  Actual label: {int(actual_labels[i])}')\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "    plot_image(i, probability_sick, actual_labels, images_bucket, threshold)\n",
    "    \n",
    "plt.savefig(model_directory+model_name+'sample_predictions.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V6E-8WBqvHog"
   },
   "source": [
    "## Add everything to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zo7tEZCS2sj2"
   },
   "outputs": [],
   "source": [
    "!cp -r $model_directory '/content/drive/My Drive/The Cool Kids/Gabi/'$model_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xj12SqD8vJ10"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "QZUtlLfYLY4n",
    "7zjIdiEC2sia",
    "THQDGwBW2sig",
    "gLhs7btS2sip",
    "M5JikHvG2siw",
    "uXcbzBV92sjK",
    "vRALTv_o2sjR",
    "Z8J3oys42sjv"
   ],
   "machine_shape": "hm",
   "name": "ModelTemplate_multimodel_for_colab.ipynb",
   "provenance": [
    {
     "file_id": "1XhR_hqlAKqo7rG-hrrEztOg3gXzPjbUL",
     "timestamp": 1564416091293
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
